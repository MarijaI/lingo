#
# Lingo-Konfiguration für den Test mit einer LIR-Datei
#
# Gebräuchliche Patterns sind
#
#   "^\021(\d+\-\d+)\022"
#   "^\[(\d+)\.\]"
#
---
meeting:

  attendees:

    ########################################
    # Text bereitstellen
    #

    # Angegebene Datei zeilenweise einlesen und verarbeiten
    - text_reader:     { files: $(files), records: true, progress: true }


    ########################################
    # Inhalte verarbeiten
    #

    # Zeile in einzelnen Sinnbestandteile (Token) zerlegen
    - tokenizer:       { }

    # Abkürzungen erkennen und auflösen
#   - abbreviator:     { source: sys-abk }

    # Verbleibende Token im Wörterbuch suchen
    - word_searcher:   { source: sys-dic, mode: first }

    # Schreibweisen variieren und erneut suchen
#   - variator:        { source: sys-dic }

    # Wortstämme für nicht erkannte Wörter einfügen
#   - stemmer:         { }

    # Nicht erkannte Wörter auf Kompositum testen
    - decomposer:      { source: sys-dic }

    # Mehrwortgruppen im Strom erkennen
    - multi_worder:    { source: sys-mul }

    # Wortsequenzen anhand von Regeln identifizieren
    - sequencer:       { stopper: 'PUNC,OTHR' }

    # Relationierungen einfügen
    - synonymer:       { skip: '?,t', source: sys-syn, out: res }


    ########################################
    # Datenstrom anzeigen
    #
#   - debugger:        { eval: 'true', ceval: 'cmd!=:EOL', prompt: 'lex:) ' }


    ########################################
    # Ergebnisse ausgeben
    #

    # Erstelle Datei mit Endung .log für Datenstrom
    - debug_filter:    { in: res, prompt: 'lex:) ' }
    - text_writer:     { ext: log, sep: "\n" }

    # Erstelle Datei mit Endung .als für Datenstrom
    - analysis_filter: { in: res }
    - text_writer:     { ext: als, sep: "\n" }

    # Erstelle Datei mit Endung .non für nicht erkannte Wörter
    - noneword_filter: { in: res }
    - text_writer:     { ext: non, sep: '|' }

    # Erstelle Datei mit Endung .ste für Wortstämme
    - vector_filter:   { in: res, lexicals: z }
    - text_writer:     { ext: ste, sep: '|' }

    # Erstelle Datei mit Endung .vec für erkannte Indexterme
    - vector_filter:   { in: res, lexicals: '^[ksavem]$' }
    - text_writer:     { ext: vec, sep: '|' }

    # Erstelle Datei mit Endung .ven für erkannte Indexterme mit absoluter Häufigkeit
    - vector_filter:   { in: res, lexicals: '^[ksavem]$', sort: term_abs }
    - text_writer:     { ext: ven, sep: '|' }

    # Erstelle Datei mit Endung .ver für erkannte Indexterme mit relativer Häufigkeit
    - vector_filter:   { in: res, lexicals: '^[ksavem]$', sort: term_rel }
    - text_writer:     { ext: ver, sep: '|' }

    # Erstelle Datei mit Endung .vef für erkannte Indexterme mit TFIDF-Gewichtung
    - vector_filter:   { in: res, lexicals: '^[ksavem]$', sort: term_rel, tfidf: true }
    - text_writer:     { ext: vef, sep: '|' }

    # Erstelle Datei mit Endung .vet für erkannte Indexterme mit Positionen
    - vector_filter:   { in: res, lexicals: '^[ksavem]$', sort: false, pos: true }
    - text_writer:     { ext: vet, sep: '|' }

    # Erstelle Datei mit Endung .mul für erkannte Mehrwortgruppen
    - vector_filter:   { in: res, lexicals: m }
    - text_writer:     { ext: mul, sep: '|' }

    # Erstelle Datei mit Endung .seq für erkannte Wortsequenzen
    - vector_filter:   { in: res, lexicals: q, sort: term_abs }
    - text_writer:     { ext: seq, sep: '|' }

    # Erstelle Datei mit Endung .syn für erkannte Synonyme
    - vector_filter:   { in: res, lexicals: y, sort: term_abs }
    - text_writer:     { ext: syn, sep: '|' }

    # Erstelle Datei mit Endung .lsi für LSI-Indexterme
#   - lsi_filter:      { in: res, lexicals: '^[ksavem]$' }
#   - text_writer:     { ext: lsi, sep: '|' }
